{
  "metadata": {
    "name": "CO2 - Spark",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\nfrom pyspark.sql import SparkSession\r\nfrom pyspark.sql.types import StringType, IntegerType, FloatType, DoubleType\r\nfrom pyspark.sql.functions import col, when, isnull, count\r\nfrom pyspark.ml.feature import VectorAssembler, StandardScaler, OneHotEncoder, StringIndexer\r\nfrom pyspark.ml import Pipeline\r\nfrom pyspark.sql.functions import col\r\nfrom pyspark.ml.regression import LinearRegression, DecisionTreeRegressor, GBTRegressor, RandomForestRegressor\r\nfrom pyspark.ml.evaluation import RegressionEvaluator\r\n\r\n%matplotlib inline\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf \u003d spark.read.csv(\"/data/co2.csv\", header\u003dTrue, inferSchema\u003dTrue)\ndf.show(5)\n"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\nrows, cols \u003d df.count(), len(df.columns)\r\nprint(f\"Nombre de lignes: {rows}, Nombre de colonnes: {cols}\")"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf.describe().show()"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndf.printSchema()"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\ndf_CO2 \u003d df\r\ndf_CO2_pd \u003d df_CO2.toPandas()\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nsns.pairplot(df_CO2_pd, kind\u003d\"reg\", diag_kind\u003d\"kde\", diag_kws\u003d{\"color\": \"red\"}, plot_kws\u003d{\"line_kws\": {\"color\": \"red\"}})"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nmakes \u003d df_CO2.select(\u0027Make\u0027).distinct().rdd.flatMap(lambda x: x).collect()\n\nco2_means \u003d []\nfor make in makes:\n    co2_mean \u003d df_CO2.filter(df_CO2[\u0027Make\u0027] \u003d\u003d make).agg({\u0027CO2_Emissions\u0027: \u0027avg\u0027}).collect()[0][0]\n    co2_means.append(co2_mean)\n\nsorted_indices \u003d np.argsort(co2_means)\nmakes_sorted \u003d [makes[i] for i in sorted_indices]\nco2_means_sorted \u003d [co2_means[i] for i in sorted_indices]\n\nnum_makes \u003d len(makes_sorted)\nfig_height \u003d max(1, num_makes * 0.2) \n\nplt.figure(figsize\u003d(8, fig_height))\nbars \u003d plt.barh(makes_sorted, co2_means_sorted, color\u003d\u0027skyblue\u0027)\nplt.title(\u0027Émissions moyennes de CO2 par marque\u0027, fontsize\u003d16)\nplt.xlabel(\u0027Émissions de CO2 (g/km)\u0027, fontsize\u003d14)\nplt.ylabel(\u0027Marque\u0027, fontsize\u003d14)\nplt.xticks(fontsize\u003d12)\nplt.yticks(fontsize\u003d12)\n\n# Ajouter les valeurs au-dessus de chaque barre\nfor bar in bars:\n    plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, \n             f\u0027{bar.get_width():.2f}\u0027, va\u003d\u0027center\u0027, ha\u003d\u0027left\u0027, fontsize\u003d10)\n\nplt.tight_layout()\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nnumerical_vars \u003d [\u0027Engine_Size\u0027, \u0027Cylinders\u0027, \u0027Fuel_Consumption_City\u0027, \u0027Fuel_Consumption_Hwy\u0027, \u0027Fuel_Consumption_Comb9\u0027, \u0027CO2_Emissions\u0027]\n\nplt.figure(figsize\u003d(12, 8))\n\nfor i, var in enumerate(numerical_vars, 1):\n    plt.subplot(2, 3, i)\n    sns.histplot(data\u003ddf_CO2_pd, x\u003dvar, kde\u003dTrue)\n    plt.title(f\u0027Boxplot of {var}\u0027)\n\nplt.tight_layout()\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nplt.figure(figsize\u003d(12, 8))\n\nfor i, var in enumerate(numerical_vars, 1):\n    plt.subplot(2, 3, i)\n    sns.boxplot(data\u003ddf_CO2_pd, y\u003dvar)\n    plt.title(f\u0027Boxplot of {var}\u0027)\n\nplt.tight_layout()\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\ndf_CO2_grouped \u003d df_CO2.groupBy(\u0027Vehicle_Class\u0027).avg(\u0027CO2_Emissions\u0027)\ndf_CO2_grouped_pd \u003d df_CO2_grouped.toPandas()\n\nplt.figure(figsize\u003d(12, 6))\nsns.barplot(data\u003ddf_CO2_grouped_pd, x\u003d\u0027Vehicle_Class\u0027, y\u003d\u0027avg(CO2_Emissions)\u0027)\nplt.title(\u0027Average CO2_Emissions by Vehicle_Class\u0027)\nplt.xticks(rotation\u003d45)\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\n\nplt.figure(figsize\u003d(8, 6))\nsns.scatterplot(data\u003ddf_CO2_pd, x\u003d\u0027Engine_Size\u0027, y\u003d\u0027CO2_Emissions\u0027, hue\u003d\u0027Cylinders\u0027, palette\u003d\u0027viridis\u0027, alpha\u003d0.7)\nplt.title(\u0027Taille du moteur par rapport aux émissions de CO2 \u0027)\nplt.xlabel(\u0027Engine_Size(L)\u0027)\nplt.ylabel(\u0027CO2_Emissions(g/km)\u0027)\nplt.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nmissing_values \u003d df.select([count(when(isnull(c), c)).alias(c) for c in df.columns])\nmissing_values.show()\n"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\n\r\nnumeric_columns \u003d [col for col, dtype in df.dtypes if dtype in [\u0027int\u0027, \u0027double\u0027]]\r\nnumeric_df_CO2 \u003d df.select(numeric_columns)\r\n\r\ncorrelation_matrix \u003d numeric_df_CO2.toPandas().corr()\r\n\r\n# Tracer la matrice de corrélation\r\nplt.figure(figsize\u003d(6, 4))\r\nsns.heatmap(correlation_matrix, annot\u003dTrue, cmap\u003d\u0027coolwarm\u0027, fmt\u003d\".2f\")\r\nplt.title(\u0027Matrice de Corrélation\u0027)\r\nplt.show()\r\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\n\r\ncat_cols \u003d [col for col in df_CO2.columns if isinstance(df_CO2.schema[col].dataType, StringType)]\r\nnum_cols \u003d [col for col in df_CO2.columns if isinstance(df_CO2.schema[col].dataType, (IntegerType, FloatType, DoubleType))]\r\n\r\nprint(\"Categorical Variables:\")\r\nprint(cat_cols)\r\nprint(\"\\n\")\r\nprint(\"Numerical Variables:\")\r\nprint(num_cols)\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ncolumns_to_drop \u003d [\u0027Make\u0027, \u0027Model\u0027, \u0027Vehicle_Class\u0027, \u0027Transmission\u0027]\ndf_CO2 \u003d df_CO2.drop(*columns_to_drop)\ndf_CO2.show(5)"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\n\r\nfrom pyspark.sql.functions import when\r\n\r\n# Liste des types de carburants uniques\r\nfuel_types \u003d df_CO2.select(\"Fuel_Type\").distinct().rdd.flatMap(lambda x: x).collect()\r\n\r\n# Ajouter des colonnes pour chaque type de carburant (one-hot encoding)\r\nfor fuel in fuel_types:\r\n    df_CO2 \u003d df_CO2.withColumn(f\"Fuel_Type_{fuel}\", when(df_CO2[\"Fuel_Type\"] \u003d\u003d fuel, True).otherwise(False))\r\n\r\ndf_CO2_ft \u003d df_CO2.drop(\"Fuel_Type\")\r\ndf_CO2_ft.show()\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\r\n# X \u003d df_CO2.drop(\u0027CO2_Emissions\u0027)\r\nX \u003d df_CO2_ft.drop(\u0027CO2_Emissions\u0027) \r\ny \u003d df_CO2_ft.select(\u0027CO2_Emissions\u0027)\r\nassembler \u003d VectorAssembler(inputCols\u003dX.columns, outputCol\u003d\"features\")\r\ndf_transformed \u003d assembler.transform(df_CO2_ft)\r\ntrain_data, test_data \u003d df_transformed.randomSplit([0.7, 0.3], seed\u003d42)\r\n\r\nprint(f\"Ensemble d\u0027entraînement : {train_data.count()} échantillons\")\r\nprint(f\"Ensemble de test : {test_data.count()} échantillons\")\r\n"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nlr \u003d LinearRegression(featuresCol\u003d\"features\", labelCol\u003d\"CO2_Emissions\")\ndt \u003d DecisionTreeRegressor(featuresCol\u003d\"features\", labelCol\u003d\"CO2_Emissions\")\nrf \u003d RandomForestRegressor(featuresCol\u003d\"features\", labelCol\u003d\"CO2_Emissions\")\ngbt \u003d GBTRegressor(featuresCol\u003d\"features\", labelCol\u003d\"CO2_Emissions\")"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\ndef train_and_evaluate(model, train_data, test_data):\n    model_fitted \u003d model.fit(train_data)\n    \n    predictions \u003d model_fitted.transform(test_data)\n    \n    evaluator \u003d RegressionEvaluator(labelCol\u003d\"CO2_Emissions\", predictionCol\u003d\"prediction\")\n    mse \u003d evaluator.setMetricName(\"mse\").evaluate(predictions)\n    rmse \u003d evaluator.setMetricName(\"rmse\").evaluate(predictions)\n    \n    return mse, rmse\n"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nresults \u003d []\nfor model, model_name in zip([lr, dt, rf, gbt], \n                             [\"LinearRegression\", \"DecisionTree\", \"RandomForest\", \"GradientBoosting\"]):\n    mse, rmse \u003d train_and_evaluate(model, train_data, test_data)\n    results.append((model_name, mse, rmse))\n\nresults_df \u003d pd.DataFrame(results, columns\u003d[\"Model\", \"MSE\", \"RMSE\"])\nprint(results_df)"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nplt.figure(figsize\u003d(8, 6))\nplt.bar(results_df[\"Model\"], results_df[\"RMSE\"], color\u003d\u0027skyblue\u0027)\nplt.xlabel(\u0027Modèles\u0027)\nplt.ylabel(\u0027RMSE\u0027)\nplt.title(\u0027Comparaison des modèles de régression\u0027)\nplt.xticks(rotation\u003d45)\nplt.show()"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nfrom pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SparkSession\n\nconf \u003d SparkConf().setAppName(\"Read-and-write-data-to-Hive-table-spark\")\nsc \u003d SparkContext.getOrCreate(conf\u003dconf)\n\nspark \u003d SparkSession.builder \\\n    .appName(\"Hive Connection Diagnostic\") \\\n    .config(\"hive.metastore.uris\", \"thrift://projet-hive-metastore-1:9083\") \\\n    .enableHiveSupport() \\\n    .getOrCreate()\ndatabase_name \u003d \"co2\"\nspark.sql(f\"CREATE DATABASE IF NOT EXISTS {database_name}\")\ndf \u003d spark.sql(\"SHOW DATABASES\")\ndf.show(truncate\u003dFalse)"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%pyspark\nspark_df \u003d spark.createDataFrame(results_df)\nspark.sql(\"USE co2\")\nspark_df.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"resultat\")\nresultat_df \u003d spark.sql(\"SELECT * FROM co2.resultat\")\nresultat_df.show()"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "format": "text/plain"
      },
      "source": "%pyspark\n"
    }
  ]
}